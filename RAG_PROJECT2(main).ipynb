{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e7ee9c-999e-416c-a7b4-920de96055aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ LOADING 'THE VERDICT' PDF\n",
      "==================================================\n",
      "‚úÖ Loaded 35 chunks from the PDF\n",
      "üöÄ RAG SYSTEM READY FOR 'THE VERDICT'\n",
      "==================================================\n",
      "\n",
      "üë§ HUMAN: What is this document about?\n",
      "ü§ñ AI: The document is about the artist Jack Gisburn who has given up painting, married a rich widow, and moved to the Riviera, much to the disappointment of his female admirers.\n",
      "   üìç From page: 1\n",
      "\n",
      "üë§ HUMAN: Who are the main characters?\n",
      "ü§ñ AI: The main character mentioned in the document is Jack Gisburn, an artist who has given up painting, married a rich widow, and moved to the Riviera. Other characters mentioned include Mrs. Gideon Thwing, Hermia Croft, Mr. Rickham, and Claude Nutley.\n",
      "   üìç From page: 1\n",
      "\n",
      "üë§ HUMAN: What is the story about?\n",
      "ü§ñ AI: The story is about artist Jack Gisburn who gives up painting, marries a rich widow, and moves to the Riviera, much to the disappointment of his female admirers and fellow artists.\n",
      "   üìç From page: 1\n",
      "\n",
      "üí¨ ASK QUESTIONS ABOUT THE DOCUMENT (type 'quit' to exit)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Your question:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Conversation ended. Chat history: 6 messages\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE RAG SYSTEM FOR \"THE VERDICT\" PDF\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. LOAD AND SPLIT THE PDF\n",
    "print(\"üìñ LOADING 'THE VERDICT' PDF\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the PDF file\n",
    "loader = PyPDFLoader(\"The_verdict.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(splits)} chunks from the PDF\")\n",
    "\n",
    "# 2. INITIALIZE CHAT MODEL\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    openai_api_key=\"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\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "# 3. SIMPLE RETRIEVER FUNCTION\n",
    "def retrieve_chunks(query, chunks, top_k=3):\n",
    "    \"\"\"Find relevant document chunks for any query\"\"\"\n",
    "    query = query.lower()\n",
    "    relevant_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        content = chunk.page_content.lower()\n",
    "        if query in content:\n",
    "            relevant_chunks.append(chunk)\n",
    "        elif any(word in content for word in query.split()):\n",
    "            relevant_chunks.append(chunk)\n",
    "    \n",
    "    return relevant_chunks[:top_k]\n",
    "\n",
    "# 4. PROMPT TEMPLATE\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the document content below.\n",
    "\n",
    "CHAT HISTORY:\n",
    "{chat_history}\n",
    "\n",
    "DOCUMENT CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "Answer based only on the document content provided.\n",
    "\"\"\"\n",
    "\n",
    "# 5. CHAT HISTORY MANAGEMENT\n",
    "chat_history = []\n",
    "\n",
    "def format_chat_history(history):\n",
    "    \"\"\"Convert LangChain messages to text\"\"\"\n",
    "    history_text = \"\"\n",
    "    for message in history:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            history_text += f\"Human: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            history_text += f\"AI: {message.content}\\n\"\n",
    "    return history_text\n",
    "\n",
    "# 6. MAIN RAG FUNCTION\n",
    "def ask_question(question):\n",
    "    \"\"\"Complete RAG pipeline for your document\"\"\"\n",
    "    global chat_history\n",
    "    \n",
    "    # Retrieve relevant chunks\n",
    "    relevant_chunks = retrieve_chunks(question, splits)\n",
    "    \n",
    "    if not relevant_chunks:\n",
    "        answer = \"I couldn't find relevant information in the document.\"\n",
    "    else:\n",
    "        # Prepare context\n",
    "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "        history_text = format_chat_history(chat_history)\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = prompt_template.format(\n",
    "            chat_history=history_text,\n",
    "            context=context,\n",
    "            question=question\n",
    "        )\n",
    "        \n",
    "        # Get answer from LLM\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "    \n",
    "    # Update chat history\n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "    chat_history.append(AIMessage(content=answer))\n",
    "    \n",
    "    return answer, relevant_chunks\n",
    "\n",
    "# 7. TEST THE SYSTEM\n",
    "print(\"üöÄ RAG SYSTEM READY FOR 'THE VERDICT'\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ask questions about the document\n",
    "questions = [\n",
    "    \"What is this document about?\",\n",
    "    \"Who are the main characters?\",\n",
    "    \"What is the story about?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nüë§ HUMAN: {question}\")\n",
    "    answer, used_chunks = ask_question(question)\n",
    "    print(f\"ü§ñ AI: {answer}\")\n",
    "    if used_chunks:\n",
    "        print(f\"   üìç From page: {used_chunks[0].metadata.get('page', 'N/A') + 1}\")\n",
    "\n",
    "# 8. INTERACTIVE CHAT\n",
    "print(\"\\nüí¨ ASK QUESTIONS ABOUT THE DOCUMENT (type 'quit' to exit)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nüë§ Your question: \").strip()\n",
    "    \n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        break\n",
    "        \n",
    "    if user_input:\n",
    "        answer, used_chunks = ask_question(user_input)\n",
    "        print(f\"ü§ñ {answer}\")\n",
    "        if used_chunks:\n",
    "            print(f\"   üìç From page: {used_chunks[0].metadata.get('page', 'N/A') + 1}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Conversation ended. Chat history: {len(chat_history)} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3c615e-5a30-48a2-8b6a-2fb236adebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is GreenGrow Innovations?\n",
      "AI: GreenGrow Innovations is a company focused on sustainable agriculture technology.\n",
      "\n",
      "Human: What was their first product?\n",
      "AI: Their first product was an AI-powered irrigation system.\n",
      "\n",
      "Human: When were they founded?\n",
      "AI: They were founded in 2018.\n",
      "\n",
      "üìã CHAT HISTORY:\n",
      "========================================\n",
      "üë§ What is GreenGrow Innovations?\n",
      "------------------------------\n",
      "ü§ñ GreenGrow Innovations is a company focused on sustainable agriculture technology.\n",
      "------------------------------\n",
      "üë§ What was their first product?\n",
      "------------------------------\n",
      "ü§ñ Their first product was an AI-powered irrigation system.\n",
      "------------------------------\n",
      "üë§ When were they founded?\n",
      "------------------------------\n",
      "ü§ñ They were founded in 2018.\n",
      "------------------------------\n",
      "\n",
      "üìä ALL SESSIONS:\n",
      "Session ID: 5abf926d-77de-4b1c-8725-610fc21bff1a\n",
      "\n",
      "üìù DETAILED HISTORY FOR SESSION 5abf926d-77de-4b1c-8725-610fc21bff1a:\n",
      "[2025-09-03 15:44:09] üë§: What is GreenGrow Innovations?\n",
      "[2025-09-03 15:44:09] ü§ñ: GreenGrow Innovations is a company focused on sustainable agriculture technology.\n",
      "\n",
      "[2025-09-03 15:44:09] üë§: What was their first product?\n",
      "[2025-09-03 15:44:09] ü§ñ: Their first product was an AI-powered irrigation system.\n",
      "\n",
      "[2025-09-03 15:44:09] üë§: When were they founded?\n",
      "[2025-09-03 15:44:09] ü§ñ: They were founded in 2018.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "DB_NAME = \"rag_app.db\"\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Create and return a database connection\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn\n",
    "\n",
    "def create_application_logs():\n",
    "    \"\"\"Create the application logs table if it doesn't exist\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    session_id TEXT,\n",
    "    user_query TEXT,\n",
    "    gpt_response TEXT,\n",
    "    model TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
    "    \"\"\"Insert a new chat interaction into the database\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
    "                 (session_id, user_query, gpt_response, model))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    \"\"\"Retrieve chat history for a specific session\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {\"role\": \"human\", \"content\": row['user_query']},\n",
    "            {\"role\": \"ai\", \"content\": row['gpt_response']}\n",
    "        ])\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "def get_all_sessions():\n",
    "    \"\"\"Get all unique session IDs\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT DISTINCT session_id FROM application_logs ORDER BY created_at DESC')\n",
    "    sessions = [row['session_id'] for row in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    return sessions\n",
    "\n",
    "def get_session_messages(session_id):\n",
    "    \"\"\"Get all messages for a specific session in chronological order\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        SELECT user_query, gpt_response, created_at \n",
    "        FROM application_logs \n",
    "        WHERE session_id = ? \n",
    "        ORDER BY created_at\n",
    "    ''', (session_id,))\n",
    "    \n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.append({\n",
    "            \"timestamp\": row['created_at'],\n",
    "            \"human\": row['user_query'],\n",
    "            \"ai\": row['gpt_response']\n",
    "        })\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "def clear_session_history(session_id):\n",
    "    \"\"\"Delete all messages for a specific session\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('DELETE FROM application_logs WHERE session_id = ?', (session_id,))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Initialize the database\n",
    "create_application_logs()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a new session\n",
    "    session_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Example conversation\n",
    "    questions_answers = [\n",
    "        (\"What is GreenGrow Innovations?\", \"GreenGrow Innovations is a company focused on sustainable agriculture technology.\"),\n",
    "        (\"What was their first product?\", \"Their first product was an AI-powered irrigation system.\"),\n",
    "        (\"When were they founded?\", \"They were founded in 2018.\")\n",
    "    ]\n",
    "    \n",
    "    # Store the conversation\n",
    "    for question, answer in questions_answers:\n",
    "        insert_application_logs(session_id, question, answer, \"gpt-3.5-turbo\")\n",
    "        print(f\"Human: {question}\")\n",
    "        print(f\"AI: {answer}\\n\")\n",
    "    \n",
    "    # Retrieve and display chat history\n",
    "    print(\"üìã CHAT HISTORY:\")\n",
    "    print(\"=\" * 40)\n",
    "    history = get_chat_history(session_id)\n",
    "    for i, message in enumerate(history):\n",
    "        if message[\"role\"] == \"human\":\n",
    "            print(f\"üë§ {message['content']}\")\n",
    "        else:\n",
    "            print(f\"ü§ñ {message['content']}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    # Show all sessions\n",
    "    print(\"\\nüìä ALL SESSIONS:\")\n",
    "    sessions = get_all_sessions()\n",
    "    for session in sessions:\n",
    "        print(f\"Session ID: {session}\")\n",
    "    \n",
    "    # Show detailed session messages\n",
    "    print(f\"\\nüìù DETAILED HISTORY FOR SESSION {session_id}:\")\n",
    "    session_messages = get_session_messages(session_id)\n",
    "    for msg in session_messages:\n",
    "        print(f\"[{msg['timestamp']}] üë§: {msg['human']}\")\n",
    "        print(f\"[{msg['timestamp']}] ü§ñ: {msg['ai']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa79bbfa-fd98-4e58-bedb-b833489718fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TABLES IN DATABASE:\n",
      " - application_logs\n",
      " - sqlite_sequence\n",
      "\n",
      "üìù ALL CHAT RECORDS:\n",
      "\n",
      "Session: 5abf926d-77de-4b1c-8725-610fc21bff1a\n",
      "Question: What is GreenGrow Innovations?\n",
      "Answer: GreenGrow Innovations is a company focused on sustainable agriculture technology.\n",
      "Model: gpt-3.5-turbo\n",
      "Time: 2025-09-03 15:44:09\n",
      "--------------------------------------------------\n",
      "\n",
      "Session: 5abf926d-77de-4b1c-8725-610fc21bff1a\n",
      "Question: What was their first product?\n",
      "Answer: Their first product was an AI-powered irrigation system.\n",
      "Model: gpt-3.5-turbo\n",
      "Time: 2025-09-03 15:44:09\n",
      "--------------------------------------------------\n",
      "\n",
      "Session: 5abf926d-77de-4b1c-8725-610fc21bff1a\n",
      "Question: When were they founded?\n",
      "Answer: They were founded in 2018.\n",
      "Model: gpt-3.5-turbo\n",
      "Time: 2025-09-03 15:44:09\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def view_database_content():\n",
    "    \"\"\"View all data in the database\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # View all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"üìä TABLES IN DATABASE:\")\n",
    "    for table in tables:\n",
    "        print(f\" - {table['name']}\")\n",
    "    \n",
    "    # View all data in application_logs\n",
    "    print(\"\\nüìù ALL CHAT RECORDS:\")\n",
    "    cursor.execute(\"SELECT * FROM application_logs ORDER BY created_at\")\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        print(f\"\\nSession: {row['session_id']}\")\n",
    "        print(f\"Question: {row['user_query']}\")\n",
    "        print(f\"Answer: {row['gpt_response']}\")\n",
    "        print(f\"Model: {row['model']}\")\n",
    "        print(f\"Time: {row['created_at']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "# Call this function to see the database\n",
    "view_database_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c28396-c43d-4154-a455-ae3ee7e97da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
